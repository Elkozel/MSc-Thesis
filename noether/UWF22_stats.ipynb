{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6b1c0f1",
   "metadata": {},
   "source": [
    "# UWF* datasets stats\n",
    "\n",
    "This notebook explores the data from the UWF22 dataset\n",
    "\n",
    "In this notebook, we explore:\n",
    "- Basic dataset stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3bf014",
   "metadata": {},
   "source": [
    "### Prepare the dataset\n",
    "\n",
    "Run the preparation for the dataset with the `prepare_data` and `setup` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4a556c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/Try1/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets.UWF22_local import UWF22L\n",
    "from datasets.UWF22H_local import UWF22HL\n",
    "from datasets.UWF22Fall_local import UWF22FallL\n",
    "from datasets.UWF24_local import UWF24L\n",
    "from datasets.UWF24Fall_local import UWF24FallL\n",
    "from ordered_set import OrderedSet\n",
    "\n",
    "possible_datasets = [\"UWF22\", \"UWF22h\", \"UWF22Fall\", \"UWF24\", \"UWF24Fall\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db4bcd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "class KeyMapGen():\n",
    "    # Exclude the mapping for the following columns\n",
    "    exclude_columns = [\n",
    "        \"ts\",\n",
    "        \"src_ip_id\",\n",
    "        \"src_ip_zeek\",\n",
    "        \"dest_ip_id\",\n",
    "        \"dest_ip_zeek\",\n",
    "        \"src_service_id\",\n",
    "        \"dest_service_id\"\n",
    "    ]\n",
    "\n",
    "    def __init__(self, dataset, output_folder) -> None:\n",
    "        self.dataset = dataset\n",
    "        self.output_folder = output_folder\n",
    "        self.key_file = os.path.join(self.output_folder, f\"{dataset.dataset_name}_keywordmap_percent.parquet\")\n",
    "        self.first_batch_passed = False\n",
    "\n",
    "    def generate_maps(self, columns):\n",
    "\n",
    "        self.keyword_map = {col: OrderedSet([]) for col in columns if col not in self.exclude_columns}\n",
    "        self.hostmap = OrderedSet([])\n",
    "        self.usermap = OrderedSet([])\n",
    "\n",
    "        # Keep track of the added values per column\n",
    "        self.added_items_per_bin = {col: [] for col in columns if col not in self.exclude_columns}\n",
    "        self.added_items_per_bin[\"hosts\"] = []\n",
    "        self.added_items_per_bin[\"services\"] = []\n",
    "        self.added_items_per_bin[\"stage\"] = []\n",
    "\n",
    "    def count_updates(self, ordered_set: OrderedSet, update):\n",
    "        set_size = len(ordered_set)\n",
    "        ordered_set.update(update)\n",
    "        new_size = len(ordered_set)\n",
    "        return new_size - set_size\n",
    "\n",
    "    def process_batch(self, batch, stage):\n",
    "        # If this is the first batch, generate the maps as well\n",
    "        if not self.first_batch_passed:\n",
    "            columns = list(batch[0].columns)\n",
    "            self.generate_maps(columns)\n",
    "            self.first_batch_passed = True\n",
    "\n",
    "        # Go trough every bin\n",
    "        for bin in batch:\n",
    "            # Update keyword map\n",
    "            for col in self.keyword_map.keys():\n",
    "                diff = self.count_updates(self.keyword_map[col], bin[col].dropna().unique())\n",
    "                self.added_items_per_bin[col].append(diff)\n",
    "            \n",
    "            diff1 = self.count_updates(self.hostmap, bin[\"src_ip_id\"].dropna().unique())\n",
    "            diff2 = self.count_updates(self.hostmap, bin[\"dest_ip_id\"].dropna().unique())\n",
    "            self.added_items_per_bin[\"hosts\"].append(diff1 + diff2)\n",
    "\n",
    "            diff1 = self.count_updates(self.usermap, bin[\"src_service_id\"].dropna().unique())\n",
    "            diff2 = self.count_updates(self.usermap, bin[\"dest_service_id\"].dropna().unique())\n",
    "            self.added_items_per_bin[\"services\"].append(diff1 + diff2)\n",
    "\n",
    "            self.added_items_per_bin[\"stage\"].append(stage)\n",
    "\n",
    "    def compute(self):\n",
    "        # If not batches have been processed\n",
    "        if not self.first_batch_passed:\n",
    "            return pd.DataFrame([])\n",
    "\n",
    "        df = pd.DataFrame(self.added_items_per_bin)\n",
    "        return df\n",
    "    \n",
    "    def save(self):\n",
    "        df = pd.DataFrame(self.added_items_per_bin)\n",
    "        df.to_parquet(self.key_file)\n",
    "        return df\n",
    "    \n",
    "    def saveplots(self, cols = [\"hosts\"]):\n",
    "        df = self.compute()\n",
    "\n",
    "        # Generate global\n",
    "        self.plot_hosts_no_stage(df, cols).savefig(os.path.join(self.output_folder, f\"{self.dataset.dataset_name}_global.svg\"))\n",
    "        # Generate with stage\n",
    "        self.plot_hosts_with_stage(df, cols).savefig(os.path.join(self.output_folder, f\"{self.dataset.dataset_name}_stage.svg\"))\n",
    "\n",
    "    \n",
    "    def showplots(self, cols = [\"hosts\"]):\n",
    "        df = pd.read_parquet(self.key_file)\n",
    "\n",
    "        # Generate global\n",
    "        self.plot_hosts_no_stage(df, cols).savefig(os.path.join(self.output_folder, f\"{self.dataset.dataset_name}_global.svg\"))\n",
    "        # Generate with stage\n",
    "        self.plot_hosts_with_stage(df, cols).savefig(os.path.join(self.output_folder, f\"{self.dataset.dataset_name}_stage.svg\"))\n",
    "\n",
    "    def plot_hosts_no_stage(self, df, cols = [\"hosts\"]):\n",
    "        clear_output(wait=True)\n",
    "        df.index = df.index/self.dataset.batch_size\n",
    "        ax = df[cols].cumsum().plot(xlabel=\"batch\", ylabel=\"Unique count\")\n",
    "        plt.title(f\"{self.dataset.dataset_name} Unique {cols}\")\n",
    "        plt.grid(True)\n",
    "        \n",
    "        return plt\n",
    "\n",
    "    def plot_hosts_with_stage(self, df: pd.DataFrame, cols = [\"hosts\"]):\n",
    "        # Sort by stage\n",
    "        df.index.name = \"index\"\n",
    "        df = df.sort_values([\"stage\", \"index\"])\n",
    "        df = df.reset_index(drop=True)\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        plt.figure(figsize=(10, 5))\n",
    "\n",
    "        # Plot the data\n",
    "        df.index = df.index/self.dataset.batch_size\n",
    "        ax = df[cols].cumsum().plot(xlabel=\"batch\", ylabel=\"Unique count\")\n",
    "\n",
    "        # Get unique stages and their x ranges\n",
    "        for stage, group in df.groupby(\"stage\"):\n",
    "            x_start = group.index.min()\n",
    "            x_end = group.index.max()\n",
    "\n",
    "            stage_label = \"Training\"\n",
    "            color = (0,1,0)\n",
    "            if stage == 1:\n",
    "                stage_label = \"Validation\"\n",
    "                color = (1,1,0)\n",
    "            if stage == 2:\n",
    "                stage_label = \"Testing\"\n",
    "                color = (1,0,0)\n",
    "\n",
    "            plt.axvspan(x_start, x_end, alpha=0.2, label=stage_label, color=color)\n",
    "\n",
    "        plt.title(f\"{self.dataset.dataset_name} Unique values by Stage\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        \n",
    "        return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddb6b44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EventCount():\n",
    "    def __init__(self, dataset, ouput_folder) -> None:\n",
    "        self.dataset = dataset\n",
    "        self.ouput_folder = ouput_folder\n",
    "        self.event_count = 0\n",
    "\n",
    "    def process_batch(self, batch, stage):\n",
    "        # Go trough every bin\n",
    "        for bin in batch:\n",
    "            # Count the events\n",
    "            self.event_count += len(bin)\n",
    "\n",
    "    def compute(self):\n",
    "        return self.event_count\n",
    "\n",
    "def database_to_df(dataset):\n",
    "    df = pd.DataFrame([])\n",
    "\n",
    "    for file in dataset.download_data:\n",
    "        filename = os.path.join(dataset.data_dir, file[\"raw_file\"])\n",
    "        part = pd.read_parquet(filename)\n",
    "        df = pd.concat([df, part])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffff7a4",
   "metadata": {},
   "source": [
    "### Graph unique (unseen) values\n",
    "This shows per time bin how many new/unseen values have been observed for every time bin.\n",
    "- x axis -> each time bin\n",
    "- y axis -> percentage of unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed07c551",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting data from batches (UWF22):  87%|████████▋ | 382/441 [15:23<00:53,  1.09it/s]  "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "dataset_folder = \"/home/thristov/mnt/noether/datasets/\"\n",
    "output_folder = \"data_stats/\"\n",
    "results = {}\n",
    "\n",
    "for dataset_name in possible_datasets:\n",
    "    # The heterogeneous variant is not needed\n",
    "    if dataset_name == \"UWF22h\":\n",
    "        continue\n",
    "\n",
    "    if dataset_name == \"UWF22\":\n",
    "        dataset = UWF22L(dataset_folder)\n",
    "    elif dataset_name == \"UWF22h\":\n",
    "        dataset = UWF22HL(dataset_folder)\n",
    "    elif dataset_name == \"UWF22Fall\":\n",
    "        dataset = UWF22FallL(dataset_folder)\n",
    "    elif dataset_name == \"UWF24\":\n",
    "        dataset = UWF24L(dataset_folder)\n",
    "    elif dataset_name == \"UWF24Fall\":\n",
    "        dataset = UWF24FallL(dataset_folder)\n",
    "    else:\n",
    "        raise Exception(f\"Dataset {dataset_name} not found\")\n",
    "\n",
    "    dataset.prepare_data()\n",
    "    dataset.setup(stage=\"fit\")\n",
    "\n",
    "    count = EventCount(dataset, output_folder)\n",
    "    keymaps = KeyMapGen(dataset, output_folder)\n",
    "\n",
    "    for batch, stage in tqdm(dataset.generate_batches(),\n",
    "                                            f\"Extracting data from batches ({dataset.dataset_name})\", total=441):\n",
    "        count.process_batch(batch, stage)\n",
    "        keymaps.process_batch(batch, stage)\n",
    "\n",
    "    keymaps.save()\n",
    "    keymaps.saveplots()\n",
    "    results[dataset_name] = {\n",
    "        \"event_count\": count.compute(),\n",
    "        \"unique_hosts\": int(keymaps.compute()[\"hosts\"].max()),\n",
    "        \"unique_services\": int(keymaps.compute()[\"services\"].max())\n",
    "    }\n",
    "\n",
    "results = pd.DataFrame(results.values())\n",
    "results.to_parquet(os.path.join(output_folder, \"stats.parquet\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
